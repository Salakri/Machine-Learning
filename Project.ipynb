{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Template is created to make grading fair and straightforward. Anything not in the place as mentioned in the template would not be graded.\n",
    "\n",
    "<font color='red'> # NOTE: We would run the notebook through a Plagiarism Checker. If it is found to be copied, your work would not be graded, and the incident would be highlighted to NYU Authorities. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# So On.......\n",
    "\n",
    "# Import data\n",
    "df_train = pd.read_csv('leaderboard_training.csv')\n",
    "df_test = pd.read_csv('leaderboard_test.csv')\n",
    "\n",
    "# Store target variable of training data\n",
    "y_train = df_train.quidditch_league_player\n",
    "\n",
    "df_train = df_train.drop(['quidditch_league_player'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values. (If ANY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of row in training and test data\n",
    "num_train = df_train.iloc[:,0].size\n",
    "num_test = df_test.iloc[:,0].size\n",
    "num_col = df_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['house', 0.022368656094317527], ['weight', 0.9685905960343767], ['player_code', 0.39555008633864597], ['move_specialty', 0.49078062044737314]]\n",
      "[['house', 0.018], ['weight', 0.97], ['player_code', 0.416], ['move_specialty', 0.492]]\n"
     ]
    }
   ],
   "source": [
    "# Process with missing values\n",
    "df_train = df_train.replace('?',np.nan)\n",
    "df_test = df_test.replace('?',np.nan)\n",
    "\n",
    "# Find the column with missing value and output the column name with its missing rate\n",
    "nan_train = df_train.isnull().sum()  \n",
    "nan_ratio_train = (nan_train/num_train).tolist()\n",
    "nan_col_name_train = df_train.columns[df_train.isnull().any()].tolist()\n",
    "\n",
    "nan_test = df_test.isnull().sum()\n",
    "nan_ratio_test = (nan_test/num_test).tolist()\n",
    "nan_col_name_test = df_test.columns[df_test.isnull().any()].tolist()\n",
    "\n",
    "j = 0\n",
    "nan_col_train = []\n",
    "for i in nan_ratio_train:\n",
    "    if i!=0:\n",
    "        nan_list = []\n",
    "        nan_list.append(nan_col_name_train[j])\n",
    "        j = j+1\n",
    "        nan_list.append(i)\n",
    "        nan_col_train.append(nan_list)\n",
    "        \n",
    "k = 0\n",
    "nan_col_test = []\n",
    "for i in nan_ratio_test:\n",
    "    if i!=0:\n",
    "        nan_list = []\n",
    "        nan_list.append(nan_col_name_test[k])\n",
    "        k = k+1\n",
    "        nan_list.append(i)\n",
    "        nan_col_test.append(nan_list)\n",
    "        \n",
    "print(nan_col_train)\n",
    "print(nan_col_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weight']\n",
      "['house', 'player_code', 'move_specialty']\n"
     ]
    }
   ],
   "source": [
    "# Put the column with more than half missing value in either training set or test set into drop list\n",
    "# Put the other column with missing value into refill list\n",
    "drop_col = []\n",
    "refill_col = []\n",
    "\n",
    "nan_num = len(nan_col_train)\n",
    "\n",
    "for flag in range(nan_num):\n",
    "    if ((nan_col_train[flag][1]>=0.5) or (nan_col_test[flag][1]>=0.5)):\n",
    "        drop_col.append(nan_col_train[flag][0])\n",
    "    else:\n",
    "        refill_col.append(nan_col_train[flag][0])\n",
    "\n",
    "print(drop_col)\n",
    "print(refill_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate training and test sets\n",
    "data = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column with more than half missing value\n",
    "for col in drop_col:\n",
    "    data = data.drop([col],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refill the other missing value with the most frequent value in this column since they are all categorical features\n",
    "for col in refill_col:\n",
    "    col_data = data[col]\n",
    "    freq = col_data.dropna().mode()[0]\n",
    "    data[col] = data[col].fillna(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Some Features or Create New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine some features together\n",
    "data['num_games_not_participate'] = data['num_games_satout']+data['num_games_injured']+data['num_games_notpartof']\n",
    "#data = data.drop(['num_games_satout','num_games_injured','num_games_notpartof'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features about the 23 tactics\n",
    "data['num_tactic_steady'] = 0\n",
    "data['num_tactic_up'] = 0\n",
    "data['num_tactic_down'] = 0\n",
    "data['num_tactic_no'] = 0\n",
    "for i in range (18,41):\n",
    "    data['num_tactic_steady'] += data[data.columns[i]].apply(lambda x: 1 if x == 'Steady' else 0)\n",
    "    data['num_tactic_up'] += data[data.columns[i]].apply(lambda x: 1 if x == 'Up' else 0)\n",
    "    data['num_tactic_down'] += data[data.columns[i]].apply(lambda x: 1 if x == 'Down' else 0)\n",
    "    data['num_tactic_no'] += data[data.columns[i]].apply(lambda x: 1 if x == 'No' else 0)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Datatype Conversion From Numeric to categoric and Vice-versa. (If ANY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform target variable into numberical data\n",
    "y_label_encoder = preprocessing.LabelEncoder()\n",
    "y_label_encoder.fit(y_train.values)\n",
    "y_train = y_label_encoder.transform(y_train.values.astype(str))\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce number of categories\n",
    "data['stooging'] = data['stooging'].replace('>7','High')\n",
    "data['stooging'] = data['stooging'].replace('>8','High')\n",
    "data['snitchnip'] = data['snitchnip'].replace('>7','High')\n",
    "data['snitchnip'] = data['snitchnip'].replace('>8','High')\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['house', 'gender', 'player_code', 'move_specialty', 'player_type', 'snitchnip', 'stooging', 'body_blow', 'checking', 'dopplebeater_defence', 'hawkshead_attacking_formation', 'no_hands_tackle', 'power_play', 'sloth_grip_roll', 'spiral_dive', 'starfish_and_stick', 'twirl', 'wronski_feint', 'zig-zag', 'bludger_backbeat', 'chelmondiston_charge', 'dionysus_dive', 'double_eight_loop', 'finbourgh_flick', 'reverse_pass', 'parkins_pincer', 'plumpton_pass', 'porskoff_ploy', 'transylvanian_tackle', 'woollongong_shimmy', 'change', 'snitch_caught']\n",
      "['id_num', 'player_id', 'age', 'foul_type_id', 'game_move_id', 'penalty_id', 'game_duration', 'num_game_moves', 'num_game_losses', 'num_practice_sessions', 'num_games_satout', 'num_games_injured', 'num_games_notpartof', 'num_games_won', 'num_games_not_participate', 'num_tactic_steady', 'num_tactic_up', 'num_tactic_down', 'num_tactic_no']\n"
     ]
    }
   ],
   "source": [
    "# Find the numerical features and categorical features\n",
    "cate_col = []\n",
    "num_col = []\n",
    "i = 0\n",
    "for columns in data:\n",
    "    if data[columns].dtypes=='object':\n",
    "        cate_col.append(columns)\n",
    "    elif (data[columns].dtypes=='int64' or data[columns].dtypes=='float64'):\n",
    "        num_col.append(columns)\n",
    "    i = i+1\n",
    "    \n",
    "print(cate_col)\n",
    "print(num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house 5 ['Gryffindor' 'Hufflepuff' 'Other' 'Ravenclaw' 'Slytherin']\n",
      "gender 3 ['Female' 'Male' 'Unknown/Invalid']\n",
      "player_code 17 ['BC' 'CH' 'CM' 'CP' 'DM' 'FR' 'HM' 'MC' 'MD' 'MP' 'OG' 'OT' 'PO' 'SI'\n",
      " 'SP' 'UN' 'WC']\n",
      "move_specialty 72 ['specialty1' 'specialty10' 'specialty11' 'specialty12' 'specialty13'\n",
      " 'specialty14' 'specialty15' 'specialty16' 'specialty17' 'specialty18'\n",
      " 'specialty19' 'specialty2' 'specialty20' 'specialty21' 'specialty22'\n",
      " 'specialty23' 'specialty24' 'specialty25' 'specialty26' 'specialty27'\n",
      " 'specialty28' 'specialty29' 'specialty3' 'specialty30' 'specialty31'\n",
      " 'specialty32' 'specialty33' 'specialty34' 'specialty35' 'specialty36'\n",
      " 'specialty37' 'specialty38' 'specialty39' 'specialty4' 'specialty40'\n",
      " 'specialty41' 'specialty42' 'specialty43' 'specialty44' 'specialty45'\n",
      " 'specialty46' 'specialty47' 'specialty48' 'specialty49' 'specialty5'\n",
      " 'specialty50' 'specialty51' 'specialty52' 'specialty53' 'specialty54'\n",
      " 'specialty55' 'specialty56' 'specialty57' 'specialty58' 'specialty59'\n",
      " 'specialty6' 'specialty60' 'specialty61' 'specialty62' 'specialty63'\n",
      " 'specialty64' 'specialty65' 'specialty66' 'specialty67' 'specialty68'\n",
      " 'specialty69' 'specialty7' 'specialty70' 'specialty71' 'specialty72'\n",
      " 'specialty8' 'specialty9']\n",
      "player_type 9 ['Beater1' 'Beater2' 'Captain' 'Chaser1' 'Chaser2' 'Chaser3' 'Keeper'\n",
      " 'Multiple' 'Seeker']\n",
      "snitchnip 4 ['>200' '>300' 'None' 'Norm']\n",
      "stooging 3 ['High' 'None' 'Norm']\n",
      "body_blow 4 ['Down' 'No' 'Steady' 'Up']\n",
      "checking 4 ['Down' 'No' 'Steady' 'Up']\n",
      "dopplebeater_defence 4 ['Down' 'No' 'Steady' 'Up']\n",
      "hawkshead_attacking_formation 4 ['Down' 'No' 'Steady' 'Up']\n",
      "no_hands_tackle 4 ['Down' 'No' 'Steady' 'Up']\n",
      "Encode: power_play\n",
      "['No' 'Steady']\n",
      "sloth_grip_roll 4 ['Down' 'No' 'Steady' 'Up']\n",
      "spiral_dive 4 ['Down' 'No' 'Steady' 'Up']\n",
      "Encode: starfish_and_stick\n",
      "['No' 'Steady']\n",
      "twirl 4 ['Down' 'No' 'Steady' 'Up']\n",
      "wronski_feint 4 ['Down' 'No' 'Steady' 'Up']\n",
      "zig-zag 4 ['Down' 'No' 'Steady' 'Up']\n",
      "bludger_backbeat 4 ['Down' 'No' 'Steady' 'Up']\n",
      "Encode: chelmondiston_charge\n",
      "['No' 'Steady']\n",
      "dionysus_dive 3 ['No' 'Steady' 'Up']\n",
      "Drop: double_eight_loop\n",
      "Drop: finbourgh_flick\n",
      "reverse_pass 4 ['Down' 'No' 'Steady' 'Up']\n",
      "parkins_pincer 4 ['Down' 'No' 'Steady' 'Up']\n",
      "Encode: plumpton_pass\n",
      "['No' 'Steady']\n",
      "Encode: porskoff_ploy\n",
      "['No' 'Steady']\n",
      "Encode: transylvanian_tackle\n",
      "['No' 'Steady']\n",
      "Encode: woollongong_shimmy\n",
      "['No' 'Steady']\n",
      "Encode: change\n",
      "['Ch' 'No']\n",
      "Encode: snitch_caught\n",
      "['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# Transform category data with 2 classes into numerical one using label encoder\n",
    "# Drop categorical column with only one class which is unnecessary\n",
    "#new_col = 0\n",
    "for col in cate_col:\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(data[col].values)\n",
    "    \n",
    "    if (len(label_encoder.classes_)==2):\n",
    "        print(\"Encode:\",col)\n",
    "        print(label_encoder.classes_)\n",
    "        data[col] = label_encoder.transform(data[col].values.astype(str))\n",
    "    elif (len(label_encoder.classes_)==1):\n",
    "        print(\"Drop:\",col)\n",
    "        data = data.drop([col],axis = 1)\n",
    "    else:\n",
    "        print(col,len(label_encoder.classes_),label_encoder.classes_)\n",
    "        #new_col += len(label_encoder.classes_)\n",
    "        \n",
    "#print(new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_num</th>\n",
       "      <th>player_id</th>\n",
       "      <th>age</th>\n",
       "      <th>foul_type_id</th>\n",
       "      <th>game_move_id</th>\n",
       "      <th>penalty_id</th>\n",
       "      <th>game_duration</th>\n",
       "      <th>num_game_moves</th>\n",
       "      <th>num_game_losses</th>\n",
       "      <th>num_practice_sessions</th>\n",
       "      <th>...</th>\n",
       "      <th>dionysus_dive_Steady</th>\n",
       "      <th>dionysus_dive_Up</th>\n",
       "      <th>reverse_pass_Down</th>\n",
       "      <th>reverse_pass_No</th>\n",
       "      <th>reverse_pass_Steady</th>\n",
       "      <th>reverse_pass_Up</th>\n",
       "      <th>parkins_pincer_Down</th>\n",
       "      <th>parkins_pincer_No</th>\n",
       "      <th>parkins_pincer_Steady</th>\n",
       "      <th>parkins_pincer_Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8222157</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>55629189</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>86047875</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>82442376</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42519267</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_num  player_id   age  foul_type_id  game_move_id  penalty_id  \\\n",
       "0       1    8222157  11.0             6            25           1   \n",
       "1       2   55629189  12.0             1             1           7   \n",
       "2       3   86047875  13.0             1             1           7   \n",
       "3       4   82442376  14.0             1             1           7   \n",
       "4       5   42519267  14.5             1             1           7   \n",
       "\n",
       "   game_duration  num_game_moves  num_game_losses  num_practice_sessions  ...  \\\n",
       "0              1              41                0                      1  ...   \n",
       "1              3              59                0                     18  ...   \n",
       "2              2              11                5                     13  ...   \n",
       "3              2              44                1                     16  ...   \n",
       "4              1              51                0                      8  ...   \n",
       "\n",
       "   dionysus_dive_Steady  dionysus_dive_Up  reverse_pass_Down  reverse_pass_No  \\\n",
       "0                     0                 0                  0                1   \n",
       "1                     0                 0                  0                0   \n",
       "2                     0                 0                  0                1   \n",
       "3                     0                 0                  0                0   \n",
       "4                     0                 0                  0                0   \n",
       "\n",
       "   reverse_pass_Steady  reverse_pass_Up  parkins_pincer_Down  \\\n",
       "0                    0                0                    0   \n",
       "1                    0                1                    0   \n",
       "2                    0                0                    0   \n",
       "3                    0                1                    0   \n",
       "4                    1                0                    0   \n",
       "\n",
       "   parkins_pincer_No  parkins_pincer_Steady  parkins_pincer_Up  \n",
       "0                  1                      0                  0  \n",
       "1                  1                      0                  0  \n",
       "2                  1                      0                  0  \n",
       "3                  1                      0                  0  \n",
       "4                  1                      0                  0  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform category data with more than 2 classes using one hot encoder\n",
    "data = pd.get_dummies(data)\n",
    "\n",
    "#for col in cate_col:\n",
    "#    onehot_encoder = preprocessing.OneHotEncoder(categories = [col[0]])\n",
    "#    data = onehot_encoder.fit_transform(data).toarray()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Reduction or extraction. (If ANY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Id columns which have no effect on result\n",
    "data = data.drop(['id_num','player_id','foul_type_id', 'game_move_id', 'penalty_id'], axis = 1)\n",
    "#data.head()\n",
    "num_col.remove('id_num')\n",
    "num_col.remove('player_id')\n",
    "num_col.remove('foul_type_id')\n",
    "num_col.remove('game_move_id')\n",
    "num_col.remove('penalty_id')\n",
    "#print(num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observing correlation matrix of features and compare the correlation between features\n",
    "corr = data.corr()\n",
    "#corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tactic_up reverse_pass_Up 0.8515325136689368\n",
      "Drop: reverse_pass_Up\n",
      "num_tactic_down reverse_pass_Down 0.9077971271509003\n",
      "Drop: reverse_pass_Down\n"
     ]
    }
   ],
   "source": [
    "# Drop one of two features that have a correlation higher than 0.75\n",
    "columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "for i in range(corr.shape[0]):\n",
    "    for j in range(i+1, corr.shape[0]):\n",
    "        if corr.iloc[i,j] >= 0.8:\n",
    "            print(data.columns[i],data.columns[j],corr.iloc[i,j])\n",
    "            if columns[j]:\n",
    "                columns[j] = False\n",
    "                print('Drop:',data.columns[j])\n",
    "\n",
    "selected_columns = data.columns[columns]\n",
    "\n",
    "data = data[selected_columns]\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Any other Pre-processing Used. (Give the name along with the code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation in columns with high skew\n",
    "log_col = ['num_games_satout', 'num_games_injured', 'num_games_notpartof', 'num_games_not_participate']\n",
    "for col in log_col:\n",
    "    data[col] = data[col].apply(lambda x: np.log(x) if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_games_satout has 4574 outliers\n",
      "Replace outliers in num_games_satout with the mean value 0.025613441403018706\n",
      "num_games_injured has 3686 outliers\n",
      "Replace outliers in num_games_injured with the mean value 0.0\n",
      "num_games_notpartof has 3623 outliers\n",
      "Replace outliers in num_games_notpartof with the mean value 0.09172725056131344\n",
      "num_games_not_participate has 2234 outliers\n",
      "Replace outliers in num_games_not_participate with the mean value 0.25854294808124534\n"
     ]
    }
   ],
   "source": [
    "# Using Standardization to process with outliers in these columns\n",
    "for col in log_col:\n",
    "    data[col + '_zscore'] = (data[col]-data[col].mean())/data[col].std()\n",
    "    abnormal_col = abs(data[col + '_zscore'])>3\n",
    "    print(col + ' has ' + str(abnormal_col.sum()) + ' outliers')\n",
    "    data.loc[abs(data[col + '_zscore'])>3, col] = np.nan\n",
    "\n",
    "    mean = data[col].dropna().mean()\n",
    "    print('Replace outliers in',col,'with the mean value',mean)\n",
    "    data[col] = data[col].fillna(mean)\n",
    "    data = data.drop([col + '_zscore'], axis=1)\n",
    "    \n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMax Normalization for numerical feature\n",
    "\n",
    "num_col.remove('num_games_injured')\n",
    "#print(num_col)\n",
    "\n",
    "for col in num_col:\n",
    "    data_min = data[col].min()\n",
    "    data_range = data[col].max()-data_min\n",
    "    data[col] = (data[col]-data_min)/data_range\n",
    "\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction using PCA\n",
    "pca = PCA(n_components = 50)\n",
    "pca_data = pca.fit_transform(data)\n",
    "new_data = pd.DataFrame(pca_data)\n",
    "#new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spilt training set and testing set\n",
    "data_train = new_data.iloc[:100766]\n",
    "data_test = new_data.iloc[100766:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original number of 1 and 0 is  11244 89522\n",
      "The number of 1 and 0 after balancing is  89522 89522\n"
     ]
    }
   ],
   "source": [
    "# Data Balancing using SMOTE\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(data_train, y_train)\n",
    "X_resampled = pd.DataFrame(X_resampled)\n",
    "#X_resampled.info()\n",
    "\n",
    "num1_before = str(y_train.tolist()).count(\"1\")\n",
    "num0_before = str(y_train.tolist()).count(\"0\")\n",
    "print('The original number of 1 and 0 is ',num1_before,num0_before)\n",
    "num1_after = str(y_resampled.tolist()).count(\"1\")\n",
    "num0_after = str(y_resampled.tolist()).count(\"0\")\n",
    "print('The number of 1 and 0 after balancing is ',num1_after,num0_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1:\n",
    "Model Name:-----------<br>\n",
    "Evaluation method and metric used Name:-----------<br>\n",
    "Name of the Hyperparameter used:--------------......<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "#Code...\n",
    "cv_params = {'n_neighbors':[2,3,5,7,11,13]}\n",
    "model = KNeighborsClassifier()\n",
    "optimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='f1', cv=5, verbose=1, n_jobs=8)\n",
    "optimized_GBM.fit(X_resampled,y_resampled)\n",
    "evaluate_result = optimized_GBM.cv_results_\n",
    "\n",
    "for i in range (0,len(evaluate_result['mean_test_score'])):\n",
    "    print(evaluate_result['params'][i],evaluate_result['mean_test_score'][i])\n",
    "    \n",
    "#print('Results for each iteration:{0}'.format(evaluate_result))\n",
    "print('Optimal value for max_depth and max_features:{0}'.format(optimized_GBM.best_params_))\n",
    "print('Best score:{0}'.format(optimized_GBM.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code...\n",
    "'''\n",
    "cv_params = {'criterion':['entropy','gini'],\n",
    "             'max_depth':[1,2,3],\n",
    "             'max_features':[6,7,8],\n",
    "             'min_samples_split':[0.5,2,3]}\n",
    "\n",
    "model = DecisionTreeClassifier(criterion = 'entropy',splitter = 'random',\n",
    "                               min_samples_leaf=1,min_weight_fraction_leaf=0.0,random_state=None,max_leaf_nodes=None,\n",
    "                               min_impurity_decrease=0.0,min_impurity_split=None,class_weight=None,presort=False)\n",
    "optimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='f1', cv=5, verbose=1, n_jobs=8)\n",
    "optimized_GBM.fit(X_resampled,y_resampled)\n",
    "evaluate_result = optimized_GBM.cv_results_\n",
    "\n",
    "for i in range (0,len(evaluate_result['mean_test_score'])):\n",
    "    print(evaluate_result['params'][i],evaluate_result['mean_test_score'][i])\n",
    "    \n",
    "#print('Results for each iteration:{0}'.format(evaluate_result))\n",
    "print('Optimal value for max_depth and max_features:{0}'.format(optimized_GBM.best_params_))\n",
    "print('Best score:{0}'.format(optimized_GBM.best_score_))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2:\n",
    "Model Name:-----------<br>\n",
    "Evaluation method and metric used Name:-----------<br>\n",
    "Name of the Hyperparameter used:--------------......<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3:\n",
    "Model Name:-----------<br>\n",
    "Evaluation method and metric used Name:-----------<br>\n",
    "Name of the Hyperparameter used:--------------......<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART III: Best Hypothesis:\n",
    "Model Name:------------<br>\n",
    "Reason:--------------<br>\n",
    "Hyper-parameter Value:-----------<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
